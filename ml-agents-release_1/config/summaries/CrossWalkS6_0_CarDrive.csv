Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,-2.1869085,819.5,-1709487.5,-1709487.5,1.0
20000,1.4161751,-7.150148,1422.375,-2043410.8220825195,-2043410.8220825195,1.0
30000,1.4136293,-11.107663,1408.8,-2299370.0,-2299370.0,1.0
40000,1.4113778,-15.679249,785.5,-1224183.3333333333,-1224183.3333333333,1.0
50000,1.4092948,-20.003422,2099.285714285714,-2059863.602042062,-2059863.602042062,1.0
60000,1.4071301,-24.048857,1102.6,-860296.3765869141,-860296.3765869141,1.0
70000,1.4054447,-27.921547,1701.6666666666667,-1127192.1517740886,-1127192.1517740886,1.0
80000,1.4035877,-31.984154,1208.5,-1074552.2307739258,-1074552.2307739258,1.0
90000,1.4018712,-36.19163,2318.0,-1618089.4605887276,-1618089.4605887276,1.0
100000,1.3996642,-40.6123,1363.3076923076924,-805224.3478299654,-805224.3478299654,1.0
110000,1.3978517,-43.859,546.9333333333333,-133441.84729003906,-133441.84729003906,1.0
120000,1.3975996,-48.01351,446.4,-182969.18940429686,-182969.18940429686,1.0
130000,1.39653,-51.972313,375.1363636363636,-153321.4894464666,-153321.4894464666,1.0
140000,1.393839,-57.218136,283.8666666666667,-92339.50896402994,-92339.50896402994,1.0
150000,1.3908216,-60.74248,440.4054054054054,-173463.23111539273,-173463.23111539273,1.0
160000,1.3892059,-65.07136,222.02083333333334,-51686.853271484375,-51686.853271484375,1.0
170000,1.38783,-68.12448,185.3148148148148,-46672.74819833261,-46672.74819833261,1.0
180000,1.3851863,-73.494415,155.43076923076924,-40173.009577824516,-40173.009577824516,1.0
190000,1.3820204,-78.63493,133.10666666666665,-31464.44698404948,-31464.44698404948,1.0
200000,1.379322,-82.813515,134.46666666666667,-24306.401005859374,-24306.401005859374,1.0
210000,1.3767095,-87.94689,110.32608695652173,-18619.507560310783,-18619.507560310783,1.0
