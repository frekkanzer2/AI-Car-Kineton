Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
360000,0.79120547,386.28787,309.5,9109.395550537109,9109.395550537109,1.0
370000,0.7911343,61.075268,330.25,8656.057941436768,8656.057941436768,1.0
380000,0.7911247,375.79926,400.15384615384613,19259.280306302586,19259.280306302586,1.0
390000,0.79106885,256.68973,1358.7333333333333,67770.21509844462,67770.21509844462,1.0
400000,0.79067546,268.98636,542.421052631579,22748.298893175626,22748.298893175626,1.0
410000,0.79036677,400.37064,327.9,14764.308484077454,14764.308484077454,1.0
420000,0.7904726,371.82648,925.7857142857143,64524.82128252302,64524.82128252302,1.0
430000,0.7905511,464.75952,542.0526315789474,31004.78092795924,31004.78092795924,1.0
440000,0.7904245,421.1062,360.7894736842105,17853.47132873535,17853.47132873535,1.0
450000,0.7904557,377.60004,682.1666666666666,44089.57083002726,44089.57083002726,1.0
460000,0.790506,319.4839,395.4375,11877.720160484314,11877.720160484314,1.0
470000,0.7903822,268.20352,815.0555555555555,52558.18170525046,52558.18170525046,1.0
480000,0.7903849,218.58647,431.0,26766.219252268475,26766.219252268475,1.0
490000,0.79038286,232.48824,711.95,27219.470540332793,27219.470540332793,1.0
500000,0.790347,273.2121,578.1052631578947,37698.48313221178,37698.48313221178,1.0
