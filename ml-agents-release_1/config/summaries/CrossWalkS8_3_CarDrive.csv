Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
470000,0.7475525,2979.903,264.8333333333333,22632.922037760418,22632.922037760418,1.0
480000,0.7476167,2698.2932,259.0,22083.007883707684,22083.007883707684,1.0
490000,0.74793094,2514.98,199.12,8944.334429321289,8944.334429321289,1.0
500000,0.74833035,2853.1023,335.7142857142857,33611.15899876186,33611.15899876186,1.0
510000,0.7483678,2522.7368,473.6,39833.92372506042,39833.92372506042,1.0
520000,0.74832135,2713.0886,450.95652173913044,13916.451629619269,13916.451629619269,1.0
530000,0.7476131,2874.3704,254.03333333333333,21716.111595662434,21716.111595662434,1.0
540000,0.74636346,2718.838,436.39130434782606,42942.876080575035,42942.876080575035,1.0
550000,0.74607944,2547.9033,246.24,17720.744107055663,17720.744107055663,1.0
560000,0.7460423,2645.9634,748.5,15269.67411170164,15269.67411170164,1.0
570000,0.7455633,2696.0125,362.11764705882354,36833.4283878102,36833.4283878102,1.0
580000,0.74550927,2600.1304,571.0833333333334,39520.300245433114,39520.300245433114,1.0
590000,0.74482095,2760.839,493.9047619047619,43407.698763166154,43407.698763166154,1.0
600000,0.74389887,2731.6143,276.12,24947.408979249,24947.408979249,1.0
610000,0.7434566,2498.0862,277.24,23392.7838270995,23392.7838270995,1.0
620000,0.7433493,2762.629,217.76190476190476,14840.544456118629,14840.544456118629,1.0
630000,0.7428145,2303.432,268.6111111111111,24001.783451928033,24001.783451928033,1.0
640000,0.743076,1944.1477,484.0869565217391,43202.81572458148,43202.81572458148,1.0
650000,0.7435156,3020.0093,693.32,16900.211099040283,16900.211099040283,1.0
660000,0.7434412,2909.4473,246.44444444444446,23394.053549024793,23394.053549024793,1.0
670000,0.74312985,2130.176,364.11538461538464,37050.93533436725,37050.93533436725,1.0
