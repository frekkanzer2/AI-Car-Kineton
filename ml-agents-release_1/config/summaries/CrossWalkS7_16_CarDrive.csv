Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,0.8388794,356.49246,297.9642857142857,31365.453224727087,31365.453224727087,1.0
20000,0.83950335,473.08218,428.2962962962963,49557.90182319054,49557.90182319054,1.0
30000,0.8390732,430.868,420.9130434782609,46967.91554196676,46967.91554196676,1.0
40000,0.8390078,436.5784,485.5238095238095,58779.27420806885,58779.27420806885,1.0
50000,0.83939964,471.19455,460.6,51184.07872009277,51184.07872009277,1.0
60000,0.8408408,514.9719,537.7894736842105,66937.85485518606,66937.85485518606,1.0
70000,0.84132725,501.26224,576.7222222222222,72631.82723151313,72631.82723151313,1.0
80000,0.8429857,576.9951,471.7894736842105,51899.71208913703,51899.71208913703,1.0
90000,0.8431042,656.373,618.7222222222222,69304.34291704964,69304.34291704964,1.0
