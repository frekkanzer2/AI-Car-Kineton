Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,0.95218444,-386.0901,477.9047619047619,109249.64387969971,109249.64387969971,1.0
20000,0.95063186,-474.13516,553.1764705882352,146952.79029719034,146952.79029719034,1.0
30000,0.9491697,-119.33317,401.6666666666667,82577.2962214152,82577.2962214152,1.0
40000,0.9454612,-134.3264,409.72727272727275,126360.44877260382,126360.44877260382,1.0
50000,0.9433875,-140.79094,621.5714285714286,230037.03945369722,230037.03945369722,1.0
60000,0.94240886,-178.15775,622.0625,159035.71109509468,159035.71109509468,1.0
70000,0.9408231,-77.43688,487.94444444444446,141334.6201717979,141334.6201717979,1.0
80000,0.93987024,50.637978,502.1363636363636,172863.61276279797,172863.61276279797,1.0
90000,0.9392132,-56.677326,464.46666666666664,128108.15740076701,128108.15740076701,1.0
100000,0.937985,101.4878,808.875,314735.4988427162,314735.4988427162,1.0
110000,0.93759567,219.23355,398.875,96396.5548470815,96396.5548470815,1.0
120000,0.9372599,304.0637,360.48275862068965,79868.67613733225,79868.67613733225,1.0
130000,0.93676925,156.5697,460.72727272727275,116317.81273033505,116317.81273033505,1.0
140000,0.9359811,181.22414,392.60869565217394,87575.51674365997,87575.51674365997,1.0
150000,0.93441486,189.91006,537.75,143705.30714874266,143705.30714874266,1.0
160000,0.9323398,152.51596,687.1428571428571,277952.07904270716,277952.07904270716,1.0
170000,0.92967623,220.78557,412.04545454545456,115282.39239380577,115282.39239380577,1.0
180000,0.92815435,105.74607,782.7857142857143,401151.3777354104,401151.3777354104,1.0
190000,0.92725444,49.817627,851.25,339385.980465889,339385.980465889,1.0
200000,0.92614996,331.00076,519.4230769230769,136114.9629650116,136114.9629650116,1.0
210000,0.9250116,205.35115,596.2666666666667,209458.6344060262,209458.6344060262,1.0
220000,0.923459,213.36449,611.6666666666666,228448.09394772848,228448.09394772848,1.0
