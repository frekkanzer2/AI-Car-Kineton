Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.1697897,-29.362743,164.83928571428572,-4677.6203327178955,-4677.6203327178955,1.0
20000,1.1703866,-36.40553,157.39655172413794,-3686.5904961947736,-3686.5904961947736,1.0
30000,1.1727008,-21.54663,186.21428571428572,-3964.2613917759486,-3964.2613917759486,1.0
40000,1.1712816,-48.24526,167.90322580645162,-4171.423308341734,-4171.423308341734,1.0
50000,1.1695544,-7.5334606,173.89285714285714,-3675.103576387678,-3675.103576387678,1.0
60000,1.1689386,-37.442085,167.44262295081967,-3600.673871399926,-3600.673871399926,1.0
70000,1.1684608,-19.289957,163.10169491525423,-3827.554019604699,-3827.554019604699,1.0
80000,1.1667602,-21.134676,169.29032258064515,-3626.5038941906346,-3626.5038941906346,1.0
