Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189384,43.50666666666667,16.189175,8.333482313036386,8.333482313036386,1.0
20000,1.4187346,18.269749518304433,45.12471,3.4294797160836774,3.4294797160836774,1.0
30000,1.4199307,11.883870967741936,59.5671,2.167096826953273,2.167096826953273,1.0
40000,1.4219682,9.19653767820774,46.521694,1.635096719160691,1.635096719160691,1.0
50000,1.4237167,6.530920060331825,43.501163,1.1243406288949007,1.1243406288949007,1.0
60000,1.4267606,5.226650062266501,50.099007,0.8572495203435088,0.8572495203435088,1.0
70000,1.4316707,4.979628520071899,25.143246,0.8066387547260266,0.8066387547260266,1.0
80000,1.438682,6.026741731175229,14.109598,0.9963483414874318,0.9963483414874318,1.0
90000,1.4423338,6.652107279693487,-1.4984722,1.1135425059824566,1.1135425059824566,1.0
100000,1.4435794,5.09640024405125,-0.16209924,0.807997587399605,0.807997587399605,1.0
