Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,0.81561667,39.63241,223.38636363636363,5338.280517231335,5338.280517231335,1.0
20000,0.81371117,130.2692,216.84782608695653,10566.243145582412,10566.243145582412,1.0
30000,0.8139439,102.80393,220.1590909090909,7975.222710782831,7975.222710782831,1.0
40000,0.8132433,195.7336,428.9166666666667,21841.479059378307,21841.479059378307,1.0
50000,0.8132254,120.24383,204.45238095238096,6785.371744288955,6785.371744288955,1.0
60000,0.8123136,118.03648,384.6551724137931,15481.146308504301,15481.146308504301,1.0
70000,0.81098604,220.11469,277.7878787878788,10429.221609231197,10429.221609231197,1.0
80000,0.8103968,116.41753,314.5625,6374.740178227425,6374.740178227425,1.0
90000,0.8095818,316.9045,424.52,23169.965740966796,23169.965740966796,1.0
100000,0.8085495,187.56686,272.72972972972974,8142.89266122354,8142.89266122354,1.0
110000,0.8086959,216.85892,307.030303030303,9775.201720844616,9775.201720844616,1.0
120000,0.8098114,298.52005,332.32142857142856,16503.343021392822,16503.343021392822,1.0
130000,0.8111783,209.2981,364.48275862068965,17052.577097925645,17052.577097925645,1.0
140000,0.81171966,282.08987,344.5,14821.745549610683,14821.745549610683,1.0
150000,0.81073576,241.2147,316.2068965517241,8849.598687035697,8849.598687035697,1.0
160000,0.81035763,239.63634,314.5483870967742,15943.416648745537,15943.416648745537,1.0
170000,0.8108129,267.60153,367.75,19137.672656740462,19137.672656740462,1.0
180000,0.8115789,208.66441,311.14285714285717,14422.144839259556,14422.144839259556,1.0
190000,0.8122146,336.14523,416.9583333333333,22373.067096710205,22373.067096710205,1.0
200000,0.8122115,280.3338,249.9375,7382.219336271286,7382.219336271286,1.0
